{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\"))\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "from tqdm import tqdm\n",
    "import scipy.io as sio\n",
    "from scipy import stats\n",
    "from scipy import sparse \n",
    "from importlib import reload\n",
    "from matplotlib import pyplot as plt\n",
    "import sys\n",
    "#sys.path.append('/home/jma819/post_cmfe_analysis')\n",
    "sys.path.append('/Users/johnmarshall/Documents/Analysis/PythonAnalysisScripts/post_cmfe_analysis')\n",
    "import python_utils_jjm as utils_jjm\n",
    "import dlc_utils\n",
    "import caiman\n",
    "import statsmodels.formula.api as smf\n",
    "import scipy.spatial.distance as dist\n",
    "import itertools\n",
    "import math\n",
    "import warnings\n",
    "import numbers\n",
    "from multiprocessing import Pool\n",
    "warnings.filterwarnings(action='once')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reload(utils_jjm)\n",
    "reload(dlc_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnmfe_file_key = pd.read_csv('/volumes/My_Passport/dlc_analysis/behavcamvideos/cnmfe_file_key.csv')\n",
    "#cnmfe_file_key = pd.read_csv('/projects/p30771/dlc_analysis/openfield_dlc_output/cnmfe_file_key.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cnmfe_base_dir = '/Volumes/My_Passport/cnmfe_analysis_files/batch_output_files/'\n",
    "#cnmfe_base_dir = '/projects/p30771/MATLAB/CNMF_E_jjm/quest_MATLAB_cnmfe/batch_output_files/'\n",
    "wt_CNMFE_file = ['30-Mar_20_39_05_out.mat', '30-Mar_20_45_16_out.mat', '27-Feb_17_33_59_out.mat', '22-Mar_22_52_02_out.mat',\n",
    "                 '28-Feb_16_10_05_out.mat', '27-Feb_17_32_15_out.mat', '28-Feb_16_21_21_out.mat', '25-Mar_13_27_27_out.mat',\n",
    "                 '25-Mar_14_22_02_out.mat', '25-Mar_14_22_44_out.mat', '26-Mar_18_33_55_out.mat', '27-Mar_00_26_12_out.mat', '27-Mar_00_48_46_out.mat']\n",
    "\n",
    "ko_CNMFE_files = ['31-Mar_13_28_15_out.mat', '29-Mar_21_42_20_out.mat', '13-Apr_17_57_40_out.mat', '29-Mar_14_27_55_out.mat', '13-Apr_16_01_20_out.mat',\n",
    "                 '13-Apr_16_11_27_out.mat', '29-Mar_13_39_44_out.mat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tracking_files = ['/volumes/My_Passport/dlc_analysis/behavcamvideos/'+utils_jjm.find_behavior_tracking(fname, cnmfe_file_key) for fname in wt_CNMFE_file] \n",
    "#tracking_files = ['/projects/p30771/dlc_analysis/openfield_dlc_output/'+utils_jjm.find_behavior_tracking(fname, cnmfe_file_key) for fname in wt_CNMFE_file] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "CNMFE_dir_paths_list = [str(cnmfe_base_dir+fname) for fname in wt_CNMFE_file]\n",
    "#CNMFE_dir_paths_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "binning_time = 1 # seconds \n",
    "body_part_for_tracking = 'tail_base' #\n",
    "number_of_bins = 50 #\n",
    "polynomial_degree = 2 #\n",
    "\n",
    "grouped_raw_data = {}\n",
    "success = []\n",
    "failed = []\n",
    "for CNMFE_file, tracking_file in zip(CNMFE_dir_paths_list, tracking_files):\n",
    "    #print(CNMFE_file)\n",
    "    #print(tracking_file)\n",
    "    try:\n",
    "        # load cell fluorescence \n",
    "        cell_fluorescence = sio.loadmat(CNMFE_file)\n",
    "        C_timedelta = utils_jjm.create_fluorescence_time_delta(cell_fluorescence['C'])\n",
    "        C_normalized = C_timedelta.apply(utils_jjm.normalize).set_index(pd.to_timedelta(np.linspace(0, (len(C_timedelta)-1)*(1/20), len(C_timedelta)), unit='s'), drop=True)\n",
    "        C_z_scored = C_timedelta.apply(stats.zscore).set_index(pd.to_timedelta(np.linspace(0, (len(C_timedelta)-1)*(1/20), len(C_timedelta)), unit='s'), drop=True)\n",
    "        C_normalized_z_scored = C_normalized.apply(stats.zscore).set_index(pd.to_timedelta(np.linspace(0, (len(C_normalized)-1)*(1/20), len(C_normalized)), unit='s'), drop=True)\n",
    "        # create tracking time deltas\n",
    "        interpolated = utils_jjm.prepare_timedelta_dfs(tracking_file)\n",
    "        #load spatial components by session\n",
    "        com_df, spatial_components = utils_jjm.return_spatial_info(CNMFE_file, 0.6)\n",
    "        cell_contours, for_dims = utils_jjm.create_contour_layouts(spatial_components)\n",
    "        #C_z_scored_filtered = utils_jjm.filter_out_by_size(C_z_scored, cell_contours, for_dims, 0.6, 100)\n",
    "        #store results \n",
    "        grouped_raw_data[tracking_file.split('/')[-2]] = {'C': C_timedelta, 'C_z_scored': C_z_scored, 'C_normalized': C_normalized, 'C_normalized_z_scored': C_normalized_z_scored, \n",
    "                                                          'interpolated' : interpolated, 'com' : com_df, 'spatial_components' : spatial_components, 'cell_contours': cell_contours,  \n",
    "                                                         'for_dims' : for_dims}\n",
    "        success.append((tracking_file.split('/')[-2], CNMFE_file.split('/')[-1]))\n",
    "    except FileNotFoundError:\n",
    "        failed.append(tracking_file)\n",
    "    except OSError:\n",
    "        failed.append(tracking_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## spatial clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## combine dfs for each session to bin velocity values across dfs\n",
    "#downsample\n",
    "new_sampling_interval = .2\n",
    "V_df = pd.concat([grouped_raw_data[session]['interpolated'].resample(str(new_sampling_interval)+'S').max() \n",
    "                  for session in list(grouped_raw_data.keys())], keys=list(grouped_raw_data.keys()))\n",
    "all_sessions_v_bins = pd.cut(V_df['tail_base'], bins=50)\n",
    "\n",
    "V_df['velocity_bins'] = all_sessions_v_bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile and filter fluorescence\n",
    "filtered_for_analysis = {}\n",
    "for session in list(grouped_raw_data.keys()):\n",
    "    filtered_for_analysis[session] = utils_jjm.filter_out_by_size(grouped_raw_data[session]['C_normalized_z_scored'], grouped_raw_data[session]['cell_contours'], \n",
    "                                                                  grouped_raw_data[session]['for_dims'], 0.6, 100)\n",
    "C_df = pd.concat([filtered_for_analysis[session].resample(str(new_sampling_interval)+'S').max()\n",
    "                  for session in list(grouped_raw_data.keys())], keys=list(grouped_raw_data.keys()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save data as sparse matricies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#session='GRIN013_H13_M33_S54'\n",
    "\n",
    "coactivity_by_session = {}\n",
    "\n",
    "for session in tqdm(list(grouped_raw_data.keys())):\n",
    "    cells_to_drop = np.array([cell for cell in range(1, len(grouped_raw_data[session]['cell_contours'])+1) if \n",
    "                              len(np.array(np.where(grouped_raw_data[session]['for_dims'][cell]>0.6)[0]))<100])\n",
    "    filtered_centers_of_mass = grouped_raw_data[session]['com'].drop(cells_to_drop, axis =0)\n",
    "    com_distances = utils_jjm.get_pairwise_distance_by_session(filtered_centers_of_mass)\n",
    "\n",
    "    ##get binned fluorescence and calc Jaccard scores\n",
    "    #arguments are sample widths to bin and z score thresholds\n",
    "    cells_in_session = C_df.loc[session].dropna(axis=1).drop('msCamFrame', axis=1)\n",
    "    binned_fluorescence = cells_in_session.apply(utils_jjm.binning_function_uncrop, args=[1, 2])\n",
    "\n",
    "    reindexed = binned_fluorescence.set_index(int(x) for x in np.linspace(0, len(binned_fluorescence)-1, len(binned_fluorescence)))\n",
    "\n",
    "#cell_keys_matrix = sparse.dok_matrix((1, len(reindexed.columns)*len(reindexed.columns)), dtype=np.float32)\n",
    "    cell_pairs = np.array([pair for pair in itertools.combinations(list(reindexed.columns), 2)])\n",
    "    coactivity_in_session = sparse.dok_matrix((len(reindexed), len(cell_pairs)))\n",
    "    for time_index in tqdm(range(len(reindexed))):\n",
    "        #coactivity_by_time_point = sparse.dok_matrix((1, len(cell_pairs)), dtype=np.float32)\n",
    "        for pair, pair_idx in zip(cell_pairs, range(len(cell_pairs))):\n",
    "            if (reindexed.loc[time_index][pair[0]] == 1) and (reindexed.loc[time_index][pair[1]] == 1):\n",
    "                coactivity_in_session[time_index, pair_idx] = 1\n",
    "            else:\n",
    "                pass \n",
    "    \n",
    "    coactivity_by_session[session]= {'coactivity_in_session': coactivity_in_session, 'cell_pairs':cell_pairs}\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save data to npz format \n",
    "for session in tqdm(list(grouped_raw_data.keys())):\n",
    "    csr_matrix = coactivity_by_session[session]['coactivity_in_session'].tocsc()\n",
    "    sparse.save_npz(\"/Users/johnmarshall/Documents/Analysis/PythonAnalysisScripts/post_cmfe_analysis/openfield_analysis/spatial_clustering/\"+str(session)+\".npz\",\n",
    "                      csr_matrix)\n",
    "    np.savetxt(\"/Users/johnmarshall/Documents/Analysis/PythonAnalysisScripts/post_cmfe_analysis/openfield_analysis/spatial_clustering/\"+str(session)+\".txt\", \n",
    "               coactivity_by_session[session]['cell_pairs'])\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load saved data and plot spatial coordination index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "spatial_coordination_by_session = {}\n",
    "for session in list(grouped_raw_data.keys()):\n",
    "    print(session)\n",
    "    session_coactivity = sparse.load_npz(\"/Users/johnmarshall/Documents/Analysis/PythonAnalysisScripts/post_cmfe_analysis/openfield_analysis/spatial_clustering/\"+str(session)+\".npz\")\n",
    "    cell_pairs = np.loadtxt(\"/Users/johnmarshall/Documents/Analysis/PythonAnalysisScripts/post_cmfe_analysis/openfield_analysis/spatial_clustering/\"+str(session)+\".txt\")\n",
    "# get indicies of small cells \n",
    "    cells_to_drop = np.array([cell for cell in range(1, len(grouped_raw_data[session]['cell_contours'])+1) if \n",
    "                          len(np.array(np.where(grouped_raw_data[session]['for_dims'][cell]>0.6)[0]))<100])\n",
    "#compile and filter cell centers of mass\n",
    "    filtered_centers_of_mass = grouped_raw_data[session]['com'].drop(cells_to_drop, axis =0)\n",
    "    com_distances = utils_jjm.get_pairwise_distance_by_session(filtered_centers_of_mass)\n",
    "\n",
    "# get one sided ks tests from h5 data set\n",
    "    binnums = 10\n",
    "    ks_one_sided_more = []\n",
    "    ks_one_sided_less = []\n",
    "    for time_point in tqdm(range(np.shape(session_coactivity)[0])):\n",
    "        active_cells = [active_cell_pair_idx[1] for active_cell_pair_idx in np.argwhere(session_coactivity[time_point])]\n",
    "        cell_ids = [sorted(cell_pairs[active_cell_idx]) for active_cell_idx in active_cells]\n",
    "        active_cell_distances = [com_distances[cell_id[0]][cell_id[1]].values[0] for cell_id in cell_ids]\n",
    "        cum_results_coactive = stats.cumfreq(active_cell_distances, numbins=binnums, defaultreallimits=(0, 500))\n",
    "        less_result = stats.kstest(cum_results_coactive.cumcount/len(active_cell_distances), 'norm', alternative='less')\n",
    "        more_result = stats.kstest(cum_results_coactive.cumcount/len(active_cell_distances), 'norm', alternative='greater')\n",
    "        ks_one_sided_more.append(more_result)\n",
    "        ks_one_sided_less.append(less_result)\n",
    "    \n",
    "    spatial_coordination_by_session[session] = {'ks_one_sided_more' : ks_one_sided_more, 'ks_one_sided_less' : ks_one_sided_less}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## compile coordination index info by session\n",
    "\n",
    "triggered_activity_across_sessions = {}\n",
    "\n",
    "for session in list(grouped_raw_data.keys()):\n",
    "    ks_one_sided_less = spatial_coordination_by_session[session]['ks_one_sided_less']\n",
    "    coord_index = np.nan_to_num([math.log(result.pvalue, 10)*-1 for result in ks_one_sided_less])\n",
    "\n",
    "    #put coordination index on time delta dataframe\n",
    "    coord_index_df = pd.DataFrame(coord_index, columns=['spatial_coordination_index'])\n",
    "    coord_index_df_time = coord_index_df.set_index(pd.to_timedelta(np.linspace(0, (len(coord_index_df)-1)*(1/5), len(coord_index_df)), unit='s'), drop=True)\n",
    "\n",
    "    # bin by activity threshold (body_part, resting_time_threshold, active_time_threshold, crossing_threshold, resting_threshold, activity_threshold)\n",
    "    binned_velocity_df = pd.DataFrame([dlc_utils.bin_by_activity_threshold(V_df.loc[session]['tail_base'], 80, 20, 1, 2, 2) for session in list(grouped_raw_data.keys())], index=list(grouped_raw_data.keys()))\n",
    "    binned_velocity_df = binned_velocity_df.transpose()\n",
    "\n",
    "    crossing_indicies = utils_jjm.select_trigger_regions(binned_velocity_df[session], 0.5, 0.5, 20)\n",
    "    #inputs time_to_plot\n",
    "    \n",
    "    threshold_activity = utils_jjm.average_triggered_regions(V_df.loc[session]['tail_base'].values, crossing_indicies, 80)\n",
    "    \n",
    "    coordination_threshold_activity = utils_jjm.average_triggered_regions(coord_index, crossing_indicies, 80)\n",
    "    \n",
    "    triggered_activity_across_sessions[session] = pd.concat([threshold_activity, coordination_threshold_activity], axis=1, keys=['velocity', 'spatial_coordination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "triggered_activity_across_sessions['GRIN013_H13_M33_S54']['spatial_coordination'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#triggered_activity_across_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#concat by mouse \n",
    "concacted_by_mouse = {}\n",
    "for mouse in list(set([session[0:7] for session in list(triggered_activity_across_sessions.keys())])):\n",
    "    dfs_by_mouse = []\n",
    "    sessions = []\n",
    "    for session in list(triggered_activity_across_sessions.keys()):\n",
    "        if mouse in session:\n",
    "            if not(triggered_activity_across_sessions[session].empty):\n",
    "                means = triggered_activity_across_sessions[session].mean(axis=1, level=0)\n",
    "                dfs_by_mouse.append(means)\n",
    "                sessions.append(session)\n",
    "    if len(dfs_by_mouse)>0:\n",
    "        concacted_by_mouse[mouse] = pd.concat(dfs_by_mouse, axis=1, keys=sessions)\n",
    "combined_by_mouse = pd.concat(list(concacted_by_mouse.values()), axis=1, keys=list(concacted_by_mouse.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined_by_mouse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(combined_by_mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "activity_measure = 'spatial_coordination'\n",
    "x = np.linspace(-(len(combined_by_mouse)/2)*.2, (len(combined_by_mouse)/2)*.2, len(combined_by_mouse))\n",
    "mean=combined_by_mouse.mean(axis=1, level=2)['velocity'].values\n",
    "plt.plot(x, combined_by_mouse.mean(axis=1, level=2)['velocity'].values, color='k')\n",
    "std_error = (combined_by_mouse.std(axis=1, level=2)['velocity'])/math.sqrt(combined_by_mouse.mean(axis=1, level=0).shape[1])\n",
    "plt.fill_between(x, mean-std_error, mean+std_error)\n",
    "ax = plt.gca()\n",
    "ax.axvline(x=(0), linestyle='--', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-(len(combined_by_mouse)/2)*.2, (len(combined_by_mouse)/2)*.2, len(combined_by_mouse))\n",
    "mean = combined_by_mouse.mean(axis=1, level=2)[activity_measure].values\n",
    "plt.plot(x, mean, color='k')\n",
    "std_error = (combined_by_mouse.std(axis=1, level=2)[activity_measure])/math.sqrt(combined_by_mouse.mean(axis=1, level=0).shape[1])\n",
    "plt.fill_between(x, mean-std_error, mean+std_error)\n",
    "ax = plt.gca()\n",
    "ax.axvline(x=0, linestyle='--', color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#parallel implementation\n",
    "def map_to_sparse_matrix(item_idx_tuple, current_row_num, sparse_matrix, orig_df_comparison):\n",
    "    if orig_df_comparison.loc[current_row_num][item[0]] == 1 and (orig_df_comparison.loc[current_row_num][item[0]] == 1):\n",
    "        sparse_matrix[current_row_num, item_idx] = 1\n",
    "    else:\n",
    "        pass\n",
    "    return(sparse_matrix)\n",
    "\n",
    "def map_to_sparse_matrix_time(time_index):\n",
    "    #for time_index in tqdm(range(len(reindexed))):\n",
    "    #coactivity_by_time_point = sparse.dok_matrix((1, len(cell_pairs)), dtype=np.float32)\n",
    "    if time_index%100 == 0:\n",
    "        print(time_index)\n",
    "    for pair, pair_idx in zip(cell_pairs, range(len(cell_pairs))):\n",
    "        if (reindexed.loc[time_index][pair[0]] == 1) and (reindexed.loc[time_index][pair[1]] == 1):\n",
    "            coactivity_in_session_p[time_index, pair_idx] = 1\n",
    "        else:\n",
    "            pass\n",
    "    return(coactivity_in_session)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# analyze by session in parallel\n",
    "\n",
    "coactivity_by_session = {}\n",
    "for session in tqdm(list(grouped_raw_data.keys())):\n",
    "    cells_to_drop = np.array([cell for cell in range(1, len(grouped_raw_data[session]['cell_contours'])+1) if \n",
    "                              len(np.array(np.where(grouped_raw_data[session]['for_dims'][cell]>0.6)[0]))<100])\n",
    "    filtered_centers_of_mass = grouped_raw_data[session]['com'].drop(cells_to_drop, axis =0)\n",
    "    com_distances = utils_jjm.get_pairwise_distance_by_session(filtered_centers_of_mass)\n",
    "\n",
    "    ##get binned fluorescence and calc Jaccard scores\n",
    "    #arguments are sample widths to bin and z score thresholds\n",
    "    cells_in_session = C_df.loc[session].dropna(axis=1).drop('msCamFrame', axis=1)\n",
    "    binned_fluorescence = cells_in_session.apply(utils_jjm.binning_function_uncrop, args=[1, 4])\n",
    "\n",
    "    reindexed = binned_fluorescence.set_index(int(x) for x in np.linspace(0, len(binned_fluorescence)-1, len(binned_fluorescence)))\n",
    "    \n",
    "    cell_pairs = np.array([pair for pair in itertools.combinations(list(reindexed.columns), 2)])\n",
    "    coactivity_in_session_p = sparse.dok_matrix((len(reindexed), len(cell_pairs)))\n",
    "\n",
    "    p=Pool(3)\n",
    "\n",
    "    coactivity_in_session = p.map(map_to_sparse_matrix_time, range(len(reindexed)))\n",
    "    coactivity_by_session[session] = coactivity_in_session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "coactivity_by_session = {}\n",
    "\n",
    "for session in tqdm(list(grouped_raw_data.keys())):\n",
    "    cells_to_drop = np.array([cell for cell in range(1, len(grouped_raw_data[session]['cell_contours'])+1) if \n",
    "                              len(np.array(np.where(grouped_raw_data[session]['for_dims'][cell]>0.6)[0]))<100])\n",
    "    filtered_centers_of_mass = grouped_raw_data[session]['com'].drop(cells_to_drop, axis =0)\n",
    "    com_distances = utils_jjm.get_pairwise_distance_by_session(filtered_centers_of_mass)\n",
    "\n",
    "    ##get binned fluorescence and calc Jaccard scores\n",
    "    #arguments are sample widths to bin and z score thresholds\n",
    "    cells_in_session = C_df.loc[session].dropna(axis=1).drop('msCamFrame', axis=1)\n",
    "    binned_fluorescence = cells_in_session.apply(utils_jjm.binning_function_uncrop, args=[1, 2])\n",
    "\n",
    "    reindexed = binned_fluorescence.set_index(int(x) for x in np.linspace(0, len(binned_fluorescence)-1, len(binned_fluorescence)))\n",
    "\n",
    "#cell_keys_matrix = sparse.dok_matrix((1, len(reindexed.columns)*len(reindexed.columns)), dtype=np.float32)\n",
    "    cell_pairs = np.array([pair for pair in itertools.combinations(list(reindexed.columns), 2)])\n",
    "    coactivity_in_session = sparse.dok_matrix((len(reindexed), len(cell_pairs)))\n",
    "    for time_index in tqdm(range(len(reindexed))):\n",
    "        #coactivity_by_time_point = sparse.dok_matrix((1, len(cell_pairs)), dtype=np.float32)\n",
    "        for pair, pair_idx in zip(cell_pairs, range(len(cell_pairs))):\n",
    "            if (reindexed.loc[time_index][pair[0]] == 1) and (reindexed.loc[time_index][pair[1]] == 1):\n",
    "                coactivity_in_session[time_index, pair_idx] = 1\n",
    "            else:\n",
    "                pass \n",
    "    \n",
    "    coactivity_by_session[session]= {'coactivity_in_session': coactivity_in_session, 'cell_pairs':cell_pairs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cell_pairs = np.array([pair for pair in itertools.combinations(list(reindexed.columns), 2)])\n",
    "coactivity_in_session_p = sparse.dok_matrix((len(reindexed), len(cell_pairs)))\n",
    "\n",
    "p=Pool(3)\n",
    "\n",
    "coactivity_in_session = p.map(map_to_sparse_matrix_time, range(len(reindexed)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "caiman",
   "language": "python",
   "name": "caiman"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
